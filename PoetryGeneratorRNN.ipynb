{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a346c09-ec5c-4072-8551-eb22014a7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9e9fb0-b07f-40fc-8cb2-2fa69fdc3e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
    "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e06ae0f-4238-42b9-8d0b-a93e2663daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(filepath, 'rb').read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a56c553-42af-4961-9cec-ae63e851084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[300000:800000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f487b2cb-cda2-4e6c-bb07-da5a928826d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))\n",
    "\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d7b6dc8-b879-4aea-8a3e-adf350094ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_char = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "187eb1a9-5195-4367-ba5d-45fc58f11447",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ed25c4a-7bb4-41d4-a8c9-75ee74945ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
    "              len(characters)), dtype=bool)\n",
    "y = np.zeros((len(sentences),\n",
    "              len(characters)), dtype=bool)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eacd6c1-f313-432c-804e-cddfee1be039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08c82b43-6927-460e-a671-6605b647a846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,\n",
    "               input_shape=(SEQ_LENGTH,\n",
    "                            len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28f09571-70ae-4361-864e-9aafaa5d6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 83ms/step - loss: 2.9244\n",
      "Epoch 2/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 95ms/step - loss: 2.3187\n",
      "Epoch 3/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 84ms/step - loss: 2.1813\n",
      "Epoch 4/4\n",
      "\u001b[1m651/651\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 101ms/step - loss: 2.0914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30872f350>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy')\n",
    "\n",
    "model.fit(x, y, batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75070355-04b8-4af7-b2e0-c1f98c1f4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "324dae56-e6b9-4cbe-9318-9341d01966b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, temperature):\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "\n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions,\n",
    "                                 temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a4a5d6f-c6c3-4c15-b83f-80c75c7360f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nd?\n",
      "\n",
      "ratcliff:\n",
      "thomas the earl of surrey the corest and and the hard in the heres.\n",
      "\n",
      "froule mery:\n",
      "what the hard the sord the counde the beater of the merest.\n",
      "\n",
      "our the reare:\n",
      "and the here the beather sould and the hard the seare.\n",
      "\n",
      "werent:\n",
      "and with the beathere sour the store sore.\n",
      "\n",
      "will there and in the beather the seares the sore.\n",
      "\n",
      "there a\n",
      "eeing ill.\n",
      "thy death-bed is no lesser that the will the merd thou bould here here her.\n",
      "\n",
      "our cordoug:\n",
      "add with searet the mery to the the soures thes and tore parking there and and thee to herch and the herd with the ground of stare.\n",
      "\n",
      "weachire:\n",
      "thear the preast the tore the cander and and of thas of i steres.\n",
      "\n",
      "condis:\n",
      "so me weren wist rome\n",
      "ve saffron to colour the warden\n",
      "pies; mare and and beather ford chand here in wilchersing\n",
      "thee sond, i the entise were stit that to be tie there.\n",
      "\n",
      "toree to sour, my rimen, brow the lofdongelas,\n",
      "and were the are the sarce to the forthy my wile shere\n",
      "so lord wither warke her thou thing core hare hith the thest thee the horst be the thene.\n",
      "\n",
      "\n",
      " the crown?\n",
      "\n",
      "king richard ii:\n",
      "ay, no; not browhtle sot and beasteres to bere,\n",
      "and cand eare the trishores my the whal there candy's vear\n",
      "and erare sounether, hever my mont eren but you starke.\n",
      "\n",
      "cormoont:\n",
      "and juty fray not what the hand a deall sourd comese\n",
      "thes it your buthing to so hers thes ard and sore.\n",
      "\n",
      "deerole,\n",
      "live:\n",
      "io a dist you sh\n",
      "dious,\n",
      "i'll tell thee what befell me on to erent.\n",
      "n thel hat seale hange se beat the urce shele\n",
      "urdes of thace ance the of ore to,\n",
      "i warther carisours, and hevencher a browed and beave,\n",
      "and ling hentenon, all thee yous'd and louthy ford ceegrst,\n",
      "fot that your whoute of or fold wich and ind.\n",
      "\n",
      "will my graigher:\n",
      "and here will on and theerse \n",
      " faintly spoke\n",
      "after the prompter, for on he lakn brile:\n",
      "thot thy uond ame roren wangeave os st ano's;\n",
      "andithy breathel, and i mary.\n",
      "\n",
      "farteen:\n",
      "and that it ancond des ood soy mes on weris seard.\n",
      "kend have mowh coor in the marester, furll your.\n",
      "\n",
      "dimest\n",
      "yourd:\n",
      "a come ay sithst to al our thay bofrome.\n",
      "wherkens my thairts, stees my trouse whar\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300, 0.2))\n",
    "print(generate_text(300, 0.4))\n",
    "print(generate_text(300, 0.5))\n",
    "print(generate_text(300, 0.6))\n",
    "print(generate_text(300, 0.7))\n",
    "print(generate_text(300, 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79fe6ea-6caa-43a9-a39c-0bb8981691a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
